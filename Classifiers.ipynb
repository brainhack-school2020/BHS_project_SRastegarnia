{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = beh_label\n",
    "#stimuli = y\n",
    "#task_mask = nonrest_task_mask\n",
    "#categories = categories\n",
    "#mask_filename = mask_vt_file\n",
    "#masker = masker\n",
    "#func_filename = func_file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML/DL models:\n",
    "\n",
    "## Different classifiers\n",
    "\n",
    "In this notebook I am willing to compare the different classifiers on a visual object recognition decoding task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from nilearn import datasets, plotting, image\n",
    "from nilearn.image import get_data\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, RidgeClassifierCV\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneGroupOut, cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate input file\n",
    "haxby_ds = datasets.fetch_haxby(subjects=[4], fetch_stimuli=True)\n",
    "\n",
    "# 'func' is a list of filenames: one for each subject\n",
    "func_file = haxby_ds.func[0]\n",
    "\n",
    "# Standardizing\n",
    "mask_vt_file = haxby_ds.mask_vt[0]\n",
    "masker = NiftiMasker(mask_img=mask_vt_file, standardize=True)\n",
    "\n",
    "# Load the behavioral data that I will predict\n",
    "beh_label = pd.read_csv(haxby_ds.session_target[0], sep=\" \")\n",
    "\n",
    "#select data\n",
    "X = masker.fit_transform(func_file)\n",
    "y = beh_label['labels']\n",
    "\n",
    "# Identify the resting state\n",
    "nonrest_task_mask = (y != 'rest')\n",
    "\n",
    "# Remove the resting state and find names of remaining active labels\n",
    "categories = y[nonrest_task_mask].unique()\n",
    "\n",
    "# Extract tags indicating to which acquisition run a tag belongs\n",
    "session_labels = beh_label['chunks'][nonrest_task_mask]\n",
    "\n",
    "masked_timecourses = masker.fit_transform(func_file)[nonrest_task_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle the data and split the sample into training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=True)\n",
    "\n",
    "#standarize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      bottle       0.08      0.17      0.11         6\n",
      "         cat       0.33      0.25      0.29        12\n",
      "       chair       0.29      0.40      0.33         5\n",
      "        face       0.44      0.50      0.47        16\n",
      "       house       0.33      0.20      0.25        10\n",
      "        rest       0.67      0.69      0.68        58\n",
      "    scissors       0.33      0.36      0.35        11\n",
      "scrambledpix       0.40      0.31      0.35        13\n",
      "        shoe       0.08      0.07      0.07        15\n",
      "\n",
      "    accuracy                           0.45       146\n",
      "   macro avg       0.33      0.33      0.32       146\n",
      "weighted avg       0.45      0.45      0.44       146\n",
      "\n",
      "Test score with L1 penalty: 0.4452\n"
     ]
    }
   ],
   "source": [
    "dtc = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "\n",
    "#train model\n",
    "dtc.fit(X_train, y_train)\n",
    "score = dtc.score(X_test, y_test)\n",
    "\n",
    "#print classification report\n",
    "dtc = dtc.predict(X_test)\n",
    "report = classification_report(y_test, dtc)\n",
    "print(report)\n",
    "\n",
    "print(\"Test score with L1 penalty: %.4f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity with L1 penalty: 0.00%\n",
      "Test score with L1 penalty: 0.7740\n"
     ]
    }
   ],
   "source": [
    "#multinomial logistic regression object using L1 penalty\n",
    "mnb = LogisticRegression(C=50., multi_class='multinomial',\n",
    "                         penalty='l1', solver='saga', tol=0.1)\n",
    "\n",
    "#train model\n",
    "mnb.fit(X_train, y_train)\n",
    "sparsity = np.mean(mnb.coef_) * 100\n",
    "score = mnb.score(X_test, y_test)\n",
    "\n",
    "# print('Best C % .4f' % clf.C_)\n",
    "print(\"Sparsity with L1 penalty: %.2f%%\" % sparsity)\n",
    "print(\"Test score with L1 penalty: %.4f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79770992 0.76628352 0.8045977  0.79310345 0.83524904]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7993887280278436"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction accuracy\n",
    "cv_scores_mnb = cross_val_score(mnb, X_train, y_train, cv=5) \n",
    "print(cv_scores_mnb)\n",
    "\n",
    "# The mean prediction accuracy\n",
    "classification_accuracy = np.mean(cv_scores_mnb)\n",
    "classification_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      bottle       0.57      1.00      0.73         8\n",
      "         cat       0.60      0.75      0.67         8\n",
      "       chair       0.62      0.62      0.62        13\n",
      "        face       1.00      0.80      0.89        15\n",
      "       house       0.83      0.83      0.83        12\n",
      "        rest       0.89      0.77      0.83        62\n",
      "    scissors       0.25      0.60      0.35         5\n",
      "scrambledpix       0.82      0.75      0.78        12\n",
      "        shoe       0.88      0.64      0.74        11\n",
      "\n",
      "    accuracy                           0.76       146\n",
      "   macro avg       0.72      0.75      0.71       146\n",
      "weighted avg       0.81      0.76      0.77       146\n",
      "\n",
      "Accuracy on test set: 76.027%\n"
     ]
    }
   ],
   "source": [
    "#shuffle the data and split the sample into training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=True)\n",
    "\n",
    "#standarize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#kneighbors classifier object\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='kd_tree', leaf_size=30, \n",
    "                           p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
    "\n",
    "#fit model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#response prediction\n",
    "pred = knn.predict(X_test)\n",
    "\n",
    "#accuracy\n",
    "knn.score(X_test, y_test)\n",
    "\n",
    "#print classification report\n",
    "knn = knn.predict(X_test)\n",
    "report = classification_report(y_test, knn)\n",
    "print(report)\n",
    "\n",
    "#evaluate accuracy\n",
    "print(\"Accuracy on test set: %0.3f%%\"%(accuracy_score(y_test, pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76335878 0.72030651 0.68582375 0.70114943 0.7164751 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.717422713579597"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='kd_tree', leaf_size=30, \n",
    "                           p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Prediction accuracy\n",
    "cv_scores_knn = cross_val_score(knn, X_train, y_train, cv=5) \n",
    "print(cv_scores_knn)\n",
    "\n",
    "# The mean prediction accuracy\n",
    "classification_accuracy_knn = np.mean(cv_scores_knn)\n",
    "classification_accuracy_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      bottle       0.33      0.12      0.18         8\n",
      "         cat       0.17      0.50      0.25         8\n",
      "       chair       0.69      0.69      0.69        13\n",
      "        face       0.00      0.00      0.00        15\n",
      "       house       0.79      0.92      0.85        12\n",
      "        rest       0.93      0.84      0.88        62\n",
      "    scissors       0.00      0.00      0.00         5\n",
      "scrambledpix       0.55      0.50      0.52        12\n",
      "        shoe       0.38      0.55      0.44        11\n",
      "\n",
      "    accuracy                           0.61       146\n",
      "   macro avg       0.43      0.46      0.42       146\n",
      "weighted avg       0.62      0.61      0.61       146\n",
      "\n",
      "Test score with L1 penalty: 0.6096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srastegarnia/miniconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/srastegarnia/miniconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#multinomial logistic regression object using L1 penalty\n",
    "nn = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "MLPClassifier(activation='logistic', alpha=1e-05, batch_size='auto',\n",
    "              beta_1=0.9, beta_2=0.999, early_stopping=False,\n",
    "              epsilon=1e-08, hidden_layer_sizes=(5, 2),\n",
    "              max_iter=200, momentum=0.9, n_iter_no_change=10,\n",
    "              nesterovs_momentum=True, power_t=0.5, random_state=1,\n",
    "              solver='lbfgs', tol=0.0001, validation_fraction=0.1, \n",
    "              verbose=False, warm_start=False)\n",
    "\n",
    "#train model\n",
    "nn.fit(X_train, y_train)\n",
    "score = nn.score(X_test, y_test)\n",
    "\n",
    "#print classification report\n",
    "nn = nn.predict(X_test)\n",
    "report = classification_report(y_test, nn)\n",
    "print(report)\n",
    "\n",
    "print(\"Test score with L1 penalty: %.4f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srastegarnia/miniconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/srastegarnia/miniconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/srastegarnia/miniconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/srastegarnia/miniconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58015267 0.60536398 0.54022989 0.60536398 0.47509579]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srastegarnia/miniconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5612412623204937"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "MLPClassifier(activation='logistic', alpha=1e-05, batch_size='auto',\n",
    "              beta_1=0.9, beta_2=0.999, early_stopping=False,\n",
    "              epsilon=1e-08, hidden_layer_sizes=(5, 2),\n",
    "              max_iter=200, momentum=0.9, n_iter_no_change=10,\n",
    "              nesterovs_momentum=True, power_t=0.5, random_state=1,\n",
    "              solver='lbfgs', tol=0.0001, validation_fraction=0.1, \n",
    "              verbose=False, warm_start=False)\n",
    "\n",
    "#train model\n",
    "nn.fit(X_train, y_train)\n",
    "\n",
    "# Prediction accuracy\n",
    "cv_scores_nn = cross_val_score(nn, X_train, y_train, cv=5) \n",
    "print(cv_scores_nn)\n",
    "\n",
    "# The mean prediction accuracy\n",
    "classification_accuracy_nn = np.mean(cv_scores_nn)\n",
    "classification_accuracy_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      bottle       0.62      0.62      0.62         8\n",
      "         cat       0.60      0.38      0.46         8\n",
      "       chair       0.73      0.85      0.79        13\n",
      "        face       0.79      1.00      0.88        15\n",
      "       house       0.85      0.92      0.88        12\n",
      "        rest       0.96      0.84      0.90        62\n",
      "    scissors       0.40      0.80      0.53         5\n",
      "scrambledpix       0.92      0.92      0.92        12\n",
      "        shoe       0.80      0.73      0.76        11\n",
      "\n",
      "    accuracy                           0.82       146\n",
      "   macro avg       0.74      0.78      0.75       146\n",
      "weighted avg       0.84      0.82      0.82       146\n",
      "\n",
      "Sparsity with L1 penalty: 0.00%\n",
      "Test score with L1 penalty: 0.8219\n"
     ]
    }
   ],
   "source": [
    "logistic_50 = LogisticRegression(C=50., multi_class='multinomial',\n",
    "                     penalty='elasticnet', solver='saga', tol=0.1, l1_ratio=0.4)\n",
    "\n",
    "#train model\n",
    "logistic_50.fit(X_train, y_train)\n",
    "sparsity = np.mean(logistic_50.coef_ == 0) * 100\n",
    "score = logistic_50.score(X_test, y_test)\n",
    "\n",
    "#print classification report\n",
    "logistic_50 = logistic_50.predict(X_test)\n",
    "report = classification_report(y_test, logistic_50)\n",
    "print(report)\n",
    "\n",
    "print(\"Sparsity with L1 penalty: %.2f%%\" % sparsity)\n",
    "print(\"Test score with L1 penalty: %.4f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76335878 0.72030651 0.68582375 0.70114943 0.7164751 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.717422713579597"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction accuracy\n",
    "cv_scores_logistic_50 = cross_val_score(knn, X_train, y_train, cv=5) \n",
    "print(cv_scores_logistic_50)\n",
    "\n",
    "# The mean prediction accuracy\n",
    "classification_accuracy_logistic_50 = np.mean(cv_scores_logistic_50)\n",
    "classification_accuracy_logistic_50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      bottle       0.45      0.62      0.53         8\n",
      "         cat       0.67      0.50      0.57         8\n",
      "       chair       0.79      0.85      0.81        13\n",
      "        face       0.93      0.87      0.90        15\n",
      "       house       0.85      0.92      0.88        12\n",
      "        rest       0.90      0.84      0.87        62\n",
      "    scissors       0.50      0.80      0.62         5\n",
      "scrambledpix       0.77      0.83      0.80        12\n",
      "        shoe       0.89      0.73      0.80        11\n",
      "\n",
      "    accuracy                           0.81       146\n",
      "   macro avg       0.75      0.77      0.75       146\n",
      "weighted avg       0.82      0.81      0.81       146\n",
      "\n",
      "Test score with L1 penalty: 0.8082\n"
     ]
    }
   ],
   "source": [
    "#standarize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "svm = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovo', degree=3, gamma='scale', kernel='linear',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "#accuracy\n",
    "score = svm.score(X_test, y_test)\n",
    "\n",
    "#print classification report\n",
    "svm = svm.predict(X_test)\n",
    "report = classification_report(y_test, svm)\n",
    "print(report)\n",
    "\n",
    "print(\"Test score with L1 penalty: %.4f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76335878 0.72030651 0.68582375 0.70114943 0.7164751 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.717422713579597"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#standarize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "svm = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovo', degree=3, gamma='scale', kernel='linear',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Prediction accuracy\n",
    "cv_scores_logistic_50 = cross_val_score(knn, X_train, y_train, cv=5) \n",
    "print(cv_scores_logistic_50)\n",
    "\n",
    "# The mean prediction accuracy\n",
    "classification_accuracy_logistic_50 = np.mean(cv_scores_logistic_50)\n",
    "classification_accuracy_logistic_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary, to hold all our classifiers\n",
    "classifiers = {'SVC': svm,\n",
    "               'LogisticRegression': logistic_50,\n",
    "               'KNeighborsClassifier':knn,\n",
    "               'DecisionTreeClassifier': dtc,\n",
    "               'MLPClassifier': nn,\n",
    "               'Multinomial Naive Bayes': mnb,\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a data splitting object for cross validation\n",
    "cv = LeaveOneGroupOut()\n",
    "\n",
    "classifiers_scores = {}\n",
    "\n",
    "for classifier_name, classifier in sorted(classifiers.items()):\n",
    "    classifiers_scores[classifier_name] = {}\n",
    "    print(70 * '_')\n",
    "\n",
    "    for category in categories:\n",
    "        classification_target = y[nonrest_task_mask].isin([category])\n",
    "        t0 = time.time()\n",
    "        classifiers_scores[classifier_name][category] = cross_val_score(\n",
    "            classifier,\n",
    "            masked_timecourses,\n",
    "            classification_target,\n",
    "            cv=5, verbose=1\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            \"%10s: %14s -- scores: %1.2f +- %1.2f, time %.2fs\" %\n",
    "            (\n",
    "                classifier_name,\n",
    "                category,\n",
    "                classifiers_scores[classifier_name][category].mean(),\n",
    "                classifiers_scores[classifier_name][category].std(),\n",
    "                time.time() - t0,\n",
    "            ),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a data splitting object for cross validation\n",
    "cv = LeaveOneGroupOut()\n",
    "\n",
    "classifiers_scores = {}\n",
    "\n",
    "for classifier_name, classifier in sorted(classifiers.items()):\n",
    "    classifiers_scores[classifier_name] = {}\n",
    "    print(70 * '_')\n",
    "\n",
    "    for category in categories:\n",
    "        classification_target = y[nonrest_task_mask].isin([category])\n",
    "        t0 = time.time()\n",
    "        classifiers_scores[classifier_name][category] = cross_val_score(\n",
    "            classifier,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            cv=5, verbose=1\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            \"%10s: %14s -- scores: %1.2f +- %1.2f, time %.2fs\" %\n",
    "            (\n",
    "                classifier_name,\n",
    "                category,\n",
    "                classifiers_scores[classifier_name][category].mean(),\n",
    "                classifiers_scores[classifier_name][category].std(),\n",
    "                time.time() - t0,\n",
    "            ),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "tick_position = np.arange(len(categories))\n",
    "plt.xticks(tick_position, categories, rotation=45)\n",
    "\n",
    "for color, classifier_name in zip(\n",
    "        ['b', 'c', 'm', 'g', 'y', 'k', '.5', 'r', '#ffaaaa'],\n",
    "        sorted(classifiers)):\n",
    "    score_means = [classifiers_scores[classifier_name][category].mean()\n",
    "                   for category in categories]\n",
    "    plt.bar(tick_position, score_means, label=classifier_name,\n",
    "            width=.11, color=color)\n",
    "    tick_position = tick_position + .09\n",
    "\n",
    "plt.ylabel('Classification accurancy (f1 score)')\n",
    "plt.xlabel('Visual stimuli category')\n",
    "plt.ylim(ymin=0)\n",
    "plt.legend(loc='lower center', ncol=3)\n",
    "plt.title(\n",
    "    'Category-specific classification accuracy for different classifiers')\n",
    "plt.tight_layout("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
